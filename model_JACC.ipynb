{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8fff3d83-a956-4236-8d79-4c52e9bc2ce3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Importing Depends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d2742a4-80e3-4e22-a8ca-844745bf07d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import cv2\n",
    "import os\n",
    "import keras\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36f6c415-15a1-4663-ac26-a2db14e376d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "for i in gpus:\n",
    "    i = tf.config.experimental.set_memory_growth(i, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84c9b21a-7f9c-46dc-8a69-100e576498d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "lr = 1e-4\n",
    "height = 1024//4\n",
    "width = 1280//4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "586e102b-65cd-4150-9fd9-0e5265cbad6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb9f89be-fd84-4e96-ba77-69140aac7b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_block(inputs, num_filters):\n",
    "    x = conv_block(inputs, num_filters)\n",
    "    p = MaxPool2D((2, 2))(x)\n",
    "    return x, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cd22d90-2fde-49fb-84b1-dee1e6ae60f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(inputs, skip, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding='same')(inputs)\n",
    "    x = Concatenate()([x, skip])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96d8d6b3-423d-44ef-b448-83f7ee573370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    s1, p1 = encoder_block(inputs, 64)\n",
    "    s2, p2 = encoder_block(p1, 128)\n",
    "    s3, p3 = encoder_block(p2, 256)\n",
    "    s4, p4 = encoder_block(p3, 512)\n",
    "\n",
    "    b1 = conv_block(p4, 1024)\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "\n",
    "    outputs = Conv2D(1, 1, padding = 'same', activation='sigmoid')(d4)\n",
    "    model = Model(inputs, outputs, name='UNET')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09d23ecb-09ee-481e-a559-3e7578234c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x, (width, height))\n",
    "    x = x/255.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2998082e-3852-4790-9440-875ce7481b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mask(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    x = cv2.resize(x, (width, height))\n",
    "    x = x/255.0\n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06164a32-818c-4a1f-b897-a3cd066ebe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_binary(image_path : str):\n",
    "    image = cv2.imread(image_path,0)\n",
    "    numpy_image = np.array([[255 if pixel == 29 else 0 for pixel in row]for row in image])\n",
    "    return numpy_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8b201ee-1631-4b49-aa13-cd1870951cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_parse(x, y):\n",
    "    def _parse(x, y):\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "        return x, y\n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float64, tf.float64])\n",
    "    x.set_shape([height, width, 3])\n",
    "    y.set_shape([height, width, 1])\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "626d97da-aaf1-4dc7-b21f-1a73c2f83573",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_dataset(x, y, batch=16):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.map(tf_parse, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f18c82b-1b0c-4957-8943-a9dc0db2b66f",
   "metadata": {},
   "source": [
    "# Driver Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3ba9abd-fd58-4716-86a1-d474399fbeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './train/'\n",
    "\n",
    "files_dir = os.path.join('files')\n",
    "model_file = os.path.join('./model/', 'unet_jacc.h5')\n",
    "log_file = os.path.join('./log/', 'log.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d2d5b0a-a105-4fa9-b1a4-b0703cba0040",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = glob(os.path.join(train_path, 'frames', '*'))\n",
    "y = glob(os.path.join(train_path, 'labels_1', '*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "818b5893-f6de-4b44-a0f3-548748baecf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, val_x, train_y, val_y = train_test_split(X, y, train_size=0.8, shuffle=False, random_state=27) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "392f5bfb-7de1-4673-821a-e3ef176e0e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1788 - 1788\n",
      "Valid: 447 - 447\n"
     ]
    }
   ],
   "source": [
    "print(f'Train: {len(train_x)} - {len(train_y)}')\n",
    "print(f'Valid: {len(val_x)} - {len(val_y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1be0f3e4-3d57-4f3f-992a-a218dc6e81e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
    "valid_dataset = tf_dataset(val_x, val_y, batch=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efa37fef-c549-4186-a4d1-eeb5d52d2541",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(2, 256, 320, 3) (2, 256, 320, 1)\n",
      "(1, 256, 320, 3) (1, 256, 320, 1)\n"
     ]
    }
   ],
   "source": [
    "# for x, y in valid_dataset:\n",
    "    # print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8110dec-b652-4250-abd9-d5de5bd16c31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"UNET\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 320, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 320, 64  1792        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 256, 320, 64  256        ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 256, 320, 64  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 256, 320, 64  36928       ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 256, 320, 64  256        ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 256, 320, 64  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 128, 160, 64  0           ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 128, 160, 12  73856       ['max_pooling2d[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 128, 160, 12  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 128, 160, 12  0           ['batch_normalization_2[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 128, 160, 12  147584      ['activation_2[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 128, 160, 12  512        ['conv2d_3[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 128, 160, 12  0           ['batch_normalization_3[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 64, 80, 128)  0          ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 64, 80, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 64, 80, 256)  1024       ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 64, 80, 256)  0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 64, 80, 256)  590080      ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 64, 80, 256)  1024       ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 64, 80, 256)  0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 32, 40, 256)  0          ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 40, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 40, 512)  2048       ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 32, 40, 512)  0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 40, 512)  2359808     ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 32, 40, 512)  2048       ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 32, 40, 512)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 16, 20, 512)  0          ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 20, 1024  4719616     ['max_pooling2d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16, 20, 1024  4096       ['conv2d_8[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 16, 20, 1024  0           ['batch_normalization_8[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 16, 20, 1024  9438208     ['activation_8[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 16, 20, 1024  4096       ['conv2d_9[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 16, 20, 1024  0           ['batch_normalization_9[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 32, 40, 512)  2097664    ['activation_9[0][0]']           \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32, 40, 1024  0           ['conv2d_transpose[0][0]',       \n",
      "                                )                                 'activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 32, 40, 512)  4719104     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 32, 40, 512)  2048       ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 32, 40, 512)  0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 32, 40, 512)  2359808     ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 32, 40, 512)  2048       ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 32, 40, 512)  0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 64, 80, 256)  524544     ['activation_11[0][0]']          \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 64, 80, 512)  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                                                  'activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 64, 80, 256)  1179904     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 64, 80, 256)  1024       ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 64, 80, 256)  0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 64, 80, 256)  590080      ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 64, 80, 256)  1024       ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 64, 80, 256)  0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 128, 160, 12  131200     ['activation_13[0][0]']          \n",
      " spose)                         8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 128, 160, 25  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                6)                                'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 128, 160, 12  295040      ['concatenate_2[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 128, 160, 12  512        ['conv2d_14[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 128, 160, 12  0           ['batch_normalization_14[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 128, 160, 12  147584      ['activation_14[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 128, 160, 12  512        ['conv2d_15[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 128, 160, 12  0           ['batch_normalization_15[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 256, 320, 64  32832      ['activation_15[0][0]']          \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 256, 320, 12  0           ['conv2d_transpose_3[0][0]',     \n",
      "                                8)                                'activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 256, 320, 64  73792       ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 256, 320, 64  256        ['conv2d_16[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 256, 320, 64  0           ['batch_normalization_16[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 256, 320, 64  36928       ['activation_16[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 256, 320, 64  256        ['conv2d_17[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 256, 320, 64  0           ['batch_normalization_17[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 256, 320, 1)  65          ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,055,297\n",
      "Trainable params: 31,043,521\n",
      "Non-trainable params: 11,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (height, width, 3)\n",
    "model = build_unet(input_shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c685858a-e3f8-4b30-81fd-bbae01f69a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance(y_true, y_pred, smooth=100):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return (1 - jac) * smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "aab287ac-4420-4ab0-8252-86c0ca7e27e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr)\n",
    "model.compile(loss = jaccard_distance, optimizer=opt, metrics=[jaccard_distance])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cf5e8ee4-e956-4e5c-840b-afb097fec36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(model_file, verbose=1, save_best_only=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2),\n",
    "    CSVLogger(log_file),\n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c6f6a6-debb-494b-8983-bd9fa5315d66",
   "metadata": {},
   "source": [
    "img_path = './PS3_Train/PS3_Train/seq_1/labels/frame020.png'\n",
    "image = cv2.imread(img_path)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "_, binary = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "binary = cv2.bitwise_not(binary)\n",
    "binary = cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR)\n",
    "result = np.where(binary == [0, 0, 0], [255, 255, 255], image)\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "547ab6e3-233c-4558-a4a4-78436331e403",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "894/894 [==============================] - ETA: 0s - loss: 0.0179 - jaccard_distance: 0.0179\n",
      "Epoch 1: val_loss improved from inf to 0.03878, saving model to ./model\\unet_jacc.h5\n",
      "894/894 [==============================] - 120s 129ms/step - loss: 0.0179 - jaccard_distance: 0.0179 - val_loss: 0.0388 - val_jaccard_distance: 0.0388 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "894/894 [==============================] - ETA: 0s - loss: 0.0156 - jaccard_distance: 0.0156\n",
      "Epoch 2: val_loss did not improve from 0.03878\n",
      "894/894 [==============================] - 114s 127ms/step - loss: 0.0156 - jaccard_distance: 0.0156 - val_loss: 0.0448 - val_jaccard_distance: 0.0448 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "894/894 [==============================] - ETA: 0s - loss: 0.0157 - jaccard_distance: 0.0157\n",
      "Epoch 3: val_loss did not improve from 0.03878\n",
      "894/894 [==============================] - 114s 128ms/step - loss: 0.0157 - jaccard_distance: 0.0157 - val_loss: 0.0452 - val_jaccard_distance: 0.0452 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "894/894 [==============================] - ETA: 0s - loss: 0.0134 - jaccard_distance: 0.0134\n",
      "Epoch 4: val_loss improved from 0.03878 to 0.03007, saving model to ./model\\unet_jacc.h5\n",
      "894/894 [==============================] - 116s 129ms/step - loss: 0.0134 - jaccard_distance: 0.0134 - val_loss: 0.0301 - val_jaccard_distance: 0.0301 - lr: 1.0000e-05\n",
      "Epoch 5/10\n",
      "894/894 [==============================] - ETA: 0s - loss: 0.0121 - jaccard_distance: 0.0121\n",
      "Epoch 5: val_loss improved from 0.03007 to 0.02934, saving model to ./model\\unet_jacc.h5\n",
      "894/894 [==============================] - 115s 129ms/step - loss: 0.0121 - jaccard_distance: 0.0121 - val_loss: 0.0293 - val_jaccard_distance: 0.0293 - lr: 1.0000e-05\n",
      "Epoch 6/10\n",
      "894/894 [==============================] - ETA: 0s - loss: 0.0115 - jaccard_distance: 0.0115\n",
      "Epoch 6: val_loss improved from 0.02934 to 0.02891, saving model to ./model\\unet_jacc.h5\n",
      "894/894 [==============================] - 115s 129ms/step - loss: 0.0115 - jaccard_distance: 0.0115 - val_loss: 0.0289 - val_jaccard_distance: 0.0289 - lr: 1.0000e-05\n",
      "Epoch 7/10\n",
      "894/894 [==============================] - ETA: 0s - loss: 0.0112 - jaccard_distance: 0.0112\n",
      "Epoch 7: val_loss improved from 0.02891 to 0.02841, saving model to ./model\\unet_jacc.h5\n",
      "894/894 [==============================] - 115s 128ms/step - loss: 0.0112 - jaccard_distance: 0.0112 - val_loss: 0.0284 - val_jaccard_distance: 0.0284 - lr: 1.0000e-05\n",
      "Epoch 8/10\n",
      "894/894 [==============================] - ETA: 0s - loss: 0.0109 - jaccard_distance: 0.0109\n",
      "Epoch 8: val_loss did not improve from 0.02841\n",
      "894/894 [==============================] - 118s 132ms/step - loss: 0.0109 - jaccard_distance: 0.0109 - val_loss: 0.0288 - val_jaccard_distance: 0.0288 - lr: 1.0000e-05\n",
      "Epoch 9/10\n",
      "894/894 [==============================] - ETA: 0s - loss: 0.0106 - jaccard_distance: 0.0106\n",
      "Epoch 9: val_loss did not improve from 0.02841\n",
      "894/894 [==============================] - 114s 128ms/step - loss: 0.0106 - jaccard_distance: 0.0106 - val_loss: 0.0288 - val_jaccard_distance: 0.0288 - lr: 1.0000e-05\n",
      "Epoch 10/10\n",
      "894/894 [==============================] - ETA: 0s - loss: 0.0105 - jaccard_distance: 0.0105\n",
      "Epoch 10: val_loss improved from 0.02841 to 0.02829, saving model to ./model\\unet_jacc.h5\n",
      "894/894 [==============================] - 115s 129ms/step - loss: 0.0105 - jaccard_distance: 0.0105 - val_loss: 0.0283 - val_jaccard_distance: 0.0283 - lr: 1.0000e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19785fabf70>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "204d7525-a9dc-4b1b-bc61-ea75ccb8c202",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./model/unet_jacc.keras')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
