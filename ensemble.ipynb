{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 07:50:40.279797: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-13 07:50:40.281165: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-13 07:50:40.310240: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-13 07:50:40.310746: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-13 07:50:40.895033: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_files = [os.path.join('/home/radhika/strykathon/unet/model', \n",
    "                            f'unet_jacc_{class_id}.keras') for class_id in range(1,7)]\n",
    "\n",
    "classes_and_colors = np.array([[0,0,0] ,[255,0,0], [25,155,187], \n",
    "                      [125,255,0], [125,255,255], [175,15,123],\n",
    "                      [141,255,12] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 1024//4\n",
    "width = 1280//4\n",
    "\n",
    "label = 2\n",
    "img_path = '/home/radhika/strykathon/unet/dataset/train/frames/frame000_seq_1.png'\n",
    "label_path = '/home/radhika/strykathon/unet/dataset/train/labels/frame000_seq_1.png'\n",
    "train_path = '/home/radhika/strykathon/unet/dataset/train'\n",
    "model_path = os.path.join('/home/radhika/strykathon/unet/model', f'unet_jacc_{label}.keras')\n",
    "# log_path = os.path.join('./log/', f'log_{label}.csv')\n",
    "# save_path = './save/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance(y_true, y_pred, smooth=100):\n",
    "    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return (1 - jac) * smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path : str):\n",
    "    return tf.keras.models.load_model(model_path, custom_objects={'jaccard_distance': jaccard_distance})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_color_of_binary_mask(image , class_id : int):\n",
    "\n",
    "    return np.array([ [ classes_and_colors[class_id] if pixel == 255 \\\n",
    "            else classes_and_colors[0] for pixel in row ] for row in image ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) /io/opencv/modules/highgui/src/precomp.hpp:155: error: (-215:Assertion failed) src_depth != CV_16F && src_depth != CV_32S in function 'convertToShow'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path,\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m img \u001b[38;5;241m=\u001b[39m change_color_of_binary_mask(image,\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m5000\u001b[39m)\n\u001b[1;32m      6\u001b[0m cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.1) /io/opencv/modules/highgui/src/precomp.hpp:155: error: (-215:Assertion failed) src_depth != CV_16F && src_depth != CV_32S in function 'convertToShow'\n"
     ]
    }
   ],
   "source": [
    "image_path = r\"/home/radhika/strykathon/unet/dataset/train/labels1/frame000_seq_1.png\"\n",
    "image = cv2.imread(image_path,0)\n",
    "img = change_color_of_binary_mask(image,1)\n",
    "cv2.imshow(\"image\",img)\n",
    "cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_wise_predicted_mask ( x , class_id ) :\n",
    "    name = x.split('/')[-1]\n",
    "    \n",
    "    x = cv2.imread ( x , cv2.IMREAD_COLOR )\n",
    "    x = cv2.resize ( x , ( width , height ) )\n",
    "    x = x / 255.0\n",
    "    x = np.expand_dims ( x , axis = 0 )\n",
    "    \n",
    "    model = load_model(model_files[class_id-1])\n",
    "\n",
    "    p = model.predict(x)[0]\n",
    "    p = np.squeeze(p, axis=-1)\n",
    "    # print ( p.shape )\n",
    "    #return p\n",
    "    cv2.imwrite(\"/home/radhika/strykathon/unet/dataset/train/predictions/pred1.png\",p)\n",
    "    # p = cv2.imread(\"/home/radhika/strykathon/unet/dataset/train/predictions/pred1.png\",0)\n",
    "    return change_color_of_binary_mask( p ,class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 668ms/step\n",
      "(256, 320, 3)\n"
     ]
    }
   ],
   "source": [
    "predicted_mask = get_class_wise_predicted_mask ( r\"/home/radhika/strykathon/unet/dataset/train/frames/frame000_seq_1.png\",1 )\n",
    "# plt.imshow(predicted_mask)\n",
    "cv2.imshow(\"random\",predicted_mask)\n",
    "cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import reduce\n",
    "\n",
    "def concatenate_masks( first_mask, second_mask ):\n",
    "    return [[ second_mask [ row_index ][ col_index ] or pixel \\\n",
    "            for col_index , pixel in enumerate ( row ) ]\\\n",
    "            for row_index , row in enumerate ( first_mask ) ]\n",
    "\n",
    "def concatenate_masks_rgb(first_mask, second_mask):\n",
    "    return [[\n",
    "        [second_mask[row_index][col_index][channel] and pixel[channel]\n",
    "         for channel in range(3)]  # Iterate over RGB channels\n",
    "        for col_index, pixel in enumerate(row)]\n",
    "        for row_index, row in enumerate(first_mask)]\n",
    "\n",
    "def concatenate_class_wise_masks ( image_path : str, num_of_classes = 6 ):\n",
    "    image = cv2.imread ( image_path )\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    blank_canvas = np.zeros(( h , w, 3 ))\n",
    "\n",
    "    predicted_masks = [ get_class_wise_predicted_mask( image_path, class_id ) \\\n",
    "                       for class_id in range ( 1 , num_of_classes + 1 )]  \n",
    "    \n",
    "    predicted_masks.append(blank_canvas)\n",
    "                                \n",
    "    return np.array(reduce( concatenate_masks_rgb , predicted_masks ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4d221e9dc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 744ms/step\n",
      "(256, 320)\n",
      "1/1 [==============================] - 1s 690ms/step\n",
      "(256, 320)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "image_path = \"/home/radhika/strykathon/unet/dataset/train/frames/frame000_seq_1.png\"\n",
    "final_img = concatenate_class_wise_masks ( image_path, 2 )\n",
    "cv2.imshow ( \"Image\", final_img )\n",
    "cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [1,2,3,4,5]\n",
    "def add ( x , y ): return x + y\n",
    "reduce(add,l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_color_of_binary_mask(image_path : str, class_id : int):\n",
    "    image = cv2.imread ( image_path , 0 )\n",
    "    return np.array([ [ classes_and_colors[class_id] if pixel == 255 \\\n",
    "            else classes_and_colors[0] for pixel in row ] for row in image ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def change_color_of_binary_mask(image_path: str, class_id : int):\n",
    "    # Read the image as grayscale\n",
    "    mask = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    mask_rgb = np.stack([mask] * 3, axis=-1)\n",
    "    \n",
    "    # Change the color of white pixels in the mask to the specified color\n",
    "    mask_rgb[mask == 255] = classes_and_colors[ class_id ]\n",
    "    \n",
    "    return mask_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "\n",
    "images = [\"/home/radhika/strykathon/unet/dataset/train/labels1/frame000_seq_7.png\",\n",
    "          \"/home/radhika/strykathon/unet/dataset/train/labels2/frame000_seq_7.png\"]\n",
    "\n",
    "masks = [ cv2.imread(image,0) for index,image in enumerate(images) ]\n",
    "\n",
    "masks = [ change_color_of_binary_mask(image,index+1)\\\n",
    "          for index,image in enumerate(images) ]\n",
    "\n",
    "masks.append ( np.zeros((1024,1280,3)) )\n",
    "final_image = np.array(reduce ( concatenate_masks_rgb , masks ))\n",
    "\n",
    "cv2.imshow(\"dekh kaun\",final_image)\n",
    "cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[11, 12, 13], [14, 2, 16]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1 = np.array([[0,0,0],[0,0,0]])\n",
    "l2 = np.array([[11,12,13],[14,2,16]])\n",
    "[[l2[row_index][col_index] or pixel for col_index,pixel in enumerate(row) ]\\\n",
    " for row_index,row in enumerate(l1)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
